# Заметки по оптимизации загрузки GPU при обучении модели

## Исходные данные

При выполнении скрипта `fine-tune/fine_tune_gemma.py` на удаленном сервере с GPU Tesla T4, команда `nvidia-smi` показала следующую информацию:

```
Mon Sep  1 12:54:20 2025
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.86.15              Driver Version: 570.86.15      CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:06.0 Off |                  Off |
| N/A   49C    P0             32W /   70W |    2667MiB /  16384MiB |     22%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A           14231      C   python3                                2664MiB |
+-----------------------------------------------------------------------------------------+
```

**Проблема:** Низкая утилизация GPU (22%) и малое использование видеопамяти (2.7GB / 16GB).

## Анализ и решение

Низкая нагрузка связана с настройками обучения в скрипте. Для ее увеличения были предложены и внесены следующие изменения в `fine-tune/fine_tune_gemma.py`:

1.  **Увеличение размера пакета (batch size):**
    *   `per_device_train_batch_size` изменен с `2` на `8`.
    *   `gradient_accumulation_steps` изменен с `4` на `1`.
    *   *Эффективный размер пакета остался прежним (8), но обработка будет происходить большими порциями, что лучше загрузит GPU.*

2.  **Отключение экономии памяти:**
    *   `use_gradient_checkpointing` изменен с `True` на `False`.
    *   *Это увеличит потребление памяти, но уберет дополнительные вычисления, что может ускорить обучение.*

Эти изменения направлены на более полную утилизацию ресурсов GPU для ускорения процесса дообучения модели.

**Возможная проблема:** Если после изменений возникнет ошибка нехватки памяти (out of memory), следует уменьшить `per_device_train_batch_size` (например, до 6 или 4).
